import { NextRequest, NextResponse } from 'next/server';

// ë°°ì¹˜ í¬ê¸° ìƒìˆ˜
const BATCH_SIZE = 50;

// í‚¤ì›Œë“œ ë°°ì¹˜ ë¶„í•  í•¨ìˆ˜
function chunkArray<T>(array: T[], size: number): T[][] {
  const chunks: T[][] = [];
  for (let i = 0; i < array.length; i += size) {
    chunks.push(array.slice(i, i + size));
  }
  return chunks;
}

// ì¬ì‹œë„ê°€ ê°€ëŠ¥í•œ ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
async function processBatchWithRetry(
  keywordBatch: string[], 
  model: string, 
  apiKey: string,
  batchIndex: number,
  maxRetries: number = 2
): Promise<{ keyword: string; stage: string }[]> {
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await processBatch(keywordBatch, model, apiKey, batchIndex, attempt);
    } catch (error) {
      console.error(`âŒ Batch ${batchIndex + 1} attempt ${attempt + 1} failed:`, error);
      
      if (attempt === maxRetries) {
        console.log(`ğŸ”„ Batch ${batchIndex + 1} failed after ${maxRetries + 1} attempts. Using fallback data.`);
        // ìµœì¢… ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ë°ì´í„° ë°˜í™˜
        return keywordBatch.map(keyword => ({
          keyword,
          stage: 'ì •ë³´ íƒìƒ‰'
        }));
      }
      
      // ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸° (exponential backoff)
      const delay = Math.pow(2, attempt) * 1000;
      console.log(`â³ Retrying batch ${batchIndex + 1} in ${delay}ms...`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
  
  // ì´ ì½”ë“œëŠ” ì‹¤í–‰ë˜ì§€ ì•Šì§€ë§Œ TypeScript ì»´íŒŒì¼ëŸ¬ë¥¼ ìœ„í•´ í•„ìš”
  return [];
}

// ë‹¨ì¼ ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
async function processBatch(
  keywordBatch: string[], 
  model: string, 
  apiKey: string,
  batchIndex: number,
  attempt: number = 0
): Promise<{ keyword: string; stage: string }[]> {
  const attemptSuffix = attempt > 0 ? ` (attempt ${attempt + 1})` : '';
  console.log(`ğŸ”„ Processing batch ${batchIndex + 1} with ${keywordBatch.length} keywords using ${model}${attemptSuffix}`);
  
  const prompt = `ë‹¤ìŒ í‚¤ì›Œë“œë“¤ì„ 6ë‹¨ê³„ êµ¬ë§¤ì—¬ì • ë‹¨ê³„ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

êµ¬ë§¤ì—¬ì • 6ë‹¨ê³„:
1. ë¬¸ì œ ì¸ì‹: ë‹ˆì¦ˆë‚˜ ë¬¸ì œë¥¼ ì²˜ìŒ ì¸ì‹í•˜ëŠ” ë‹¨ê³„ (ì˜ˆ: "ì¹´í˜ë€", "ì°½ì—…ì´ë€", "ë¬¸ì œì ")
2. ì •ë³´ íƒìƒ‰: í•´ê²°ì±…ì„ ì°¾ê¸° ìœ„í•´ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ë‹¨ê³„ (ì˜ˆ: "ì¹´í˜ ì¶”ì²œ", "ì°½ì—… ë°©ë²•", "ì¢…ë¥˜")
3. ëŒ€ì•ˆ í‰ê°€: ì—¬ëŸ¬ ëŒ€ì•ˆì„ ë¹„êµ ê²€í† í•˜ëŠ” ë‹¨ê³„ (ì˜ˆ: "ì¹´í˜ ë¹„êµ", "A vs B", "ì¥ë‹¨ì ")
4. êµ¬ë§¤ ê²°ì •: íŠ¹ì • ì œí’ˆ/ì„œë¹„ìŠ¤ êµ¬ë§¤ë¥¼ ê²°ì •í•˜ëŠ” ë‹¨ê³„ (ì˜ˆ: "ì¹´í˜ ê°€ê²©", "ë¹„ìš©", "í• ì¸")
5. êµ¬ë§¤ í–‰ë™: ì‹¤ì œ êµ¬ë§¤ í–‰ë™ì´ ì¼ì–´ë‚˜ëŠ” ë‹¨ê³„ (ì˜ˆ: "ì¹´í˜ êµ¬ë§¤", "ì£¼ë¬¸", "ì˜ˆì•½")
6. êµ¬ë§¤ í›„ í–‰ë™: êµ¬ë§¤ í›„ ë§Œì¡±ë„ë¥¼ í‰ê°€í•˜ëŠ” ë‹¨ê³„ (ì˜ˆ: "ì¹´í˜ í›„ê¸°", "ë¦¬ë·°", "í‰ê°€")

ë‹¤ìŒ í‚¤ì›Œë“œë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
${keywordBatch.map((k: string, i: number) => `${i + 1}. ${k}`).join('\n')}

ê° í‚¤ì›Œë“œì— ëŒ€í•´ ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
í‚¤ì›Œë“œëª…|ë‹¨ê³„ëª…

ì •í™•í•œ ì˜ˆì‹œ:
ì¹´í˜ ì¶”ì²œ|ì •ë³´ íƒìƒ‰
ì¹´í˜ ì°½ì—… ë¹„ìš©|êµ¬ë§¤ ê²°ì •
ì¹´í˜ í›„ê¸°|êµ¬ë§¤ í›„ í–‰ë™`;

  // ëª¨ë¸ë³„ ì„¤ì • ê²°ì •
  const getModelConfig = (selectedModel: string) => {
    if (selectedModel.startsWith('gpt-5')) {
      return {
        apiUrl: 'https://api.openai.com/v1/responses',
        body: {
          model: selectedModel,
          input: `ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ ë³´ê³  êµ¬ë§¤ì—¬ì • ë‹¨ê³„ë¥¼ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.\n\n${prompt}`,
          reasoning: {
            effort: selectedModel === 'gpt-5' ? 'medium' : 'low'
          },
          text: {
            verbosity: selectedModel === 'gpt-5-nano' ? 'medium' : 'high'
          }
        }
      };
    } else {
      return {
        apiUrl: 'https://api.openai.com/v1/chat/completions',
        body: {
          model: selectedModel,
          messages: [
            {
              role: 'system',
              content: 'ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ ë³´ê³  êµ¬ë§¤ì—¬ì • ë‹¨ê³„ë¥¼ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.'
            },
            {
              role: 'user',
              content: prompt
            }
          ],
          temperature: 0.3,
          max_tokens: 2000
        }
      };
    }
  };

  const config = getModelConfig(model);

  const response = await fetch(config.apiUrl, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${apiKey}`,
    },
    body: JSON.stringify(config.body),
  });

  if (!response.ok) {
    const errorData = await response.text();
    console.error(`âŒ Batch ${batchIndex + 1} API Error:`, errorData);
    throw new Error(`Batch ${batchIndex + 1} failed: ${response.status} ${response.statusText}`);
  }

  const data = await response.json();
  
  // ëª¨ë¸ë³„ ì‘ë‹µ íŒŒì‹±
  let content = '';
  if (model.startsWith('gpt-5')) {
    content = data.output_text || '';
  } else {
    content = data.choices?.[0]?.message?.content || '';
  }
  
  console.log(`ğŸ“ Batch ${batchIndex + 1} ${model} Raw Response:`, content);
  
  // ì‘ë‹µ íŒŒì‹±
  const results = content.split('\n')
    .filter((line: string) => line.includes('|'))
    .map((line: string) => {
      const [keyword, stage] = line.split('|').map(s => s.trim());
      return { keyword, stage };
    });

  console.log(`ğŸ” Batch ${batchIndex + 1} Parsed Results:`, results);

  // ë§¤ì¹­ë˜ì§€ ì•Šì€ í‚¤ì›Œë“œì— ëŒ€í•´ ê¸°ë³¸ê°’ ì„¤ì •
  const finalResults = keywordBatch.map((keyword: string) => {
    const result = results.find(r => r.keyword === keyword);
    return {
      keyword,
      stage: result?.stage || 'ì •ë³´ íƒìƒ‰',
    };
  });

  console.log(`âœ… Batch ${batchIndex + 1} Final Results:`, finalResults);
  return finalResults;
}

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { keywords, model = 'gpt-5-nano' } = body;

    if (!keywords || !Array.isArray(keywords) || keywords.length === 0) {
      return NextResponse.json(
        { error: 'Keywords are required' },
        { status: 400 }
      );
    }

    const apiKey = process.env.OPENAI_API_KEY;

    // OpenAI API í‚¤ê°€ ì—†ëŠ” ê²½ìš° ë”ë¯¸ ë°ì´í„° ë°˜í™˜
    if (!apiKey) {
      console.log('âš ï¸ OpenAI API key not configured. Returning DUMMY DATA.');
      
      // ë”ë¯¸ ë°ì´í„°: í‚¤ì›Œë“œ íŒ¨í„´ì— ë”°ë¼ êµ¬ë§¤ì—¬ì • ë‹¨ê³„ í• ë‹¹
      const dummyResults = keywords.map((keyword: string) => {
        let stage = 'ì •ë³´ íƒìƒ‰'; // ê¸°ë³¸ê°’
        
        const lowerKeyword = keyword.toLowerCase();
        
        // í‚¤ì›Œë“œ íŒ¨í„´ì— ë”°ë¥¸ ë‹¨ê³„ ë§¤ì¹­
        if (lowerKeyword.includes('ì´ë€') || lowerKeyword.includes('ëœ»') || lowerKeyword.includes('ê°œë…') || lowerKeyword.includes('ë¬¸ì œì ')) {
          stage = 'ë¬¸ì œ ì¸ì‹';
        } else if (lowerKeyword.includes('ì¶”ì²œ') || lowerKeyword.includes('ì¢…ë¥˜') || lowerKeyword.includes('ë°©ë²•') || lowerKeyword.includes('ì •ë³´')) {
          stage = 'ì •ë³´ íƒìƒ‰';
        } else if (lowerKeyword.includes('ë¹„êµ') || lowerKeyword.includes('vs') || lowerKeyword.includes('ì°¨ì´') || lowerKeyword.includes('ì¥ë‹¨ì ')) {
          stage = 'ëŒ€ì•ˆ í‰ê°€';
        } else if (lowerKeyword.includes('ê°€ê²©') || lowerKeyword.includes('í• ì¸') || lowerKeyword.includes('ìµœì €ê°€') || lowerKeyword.includes('ë¹„ìš©')) {
          stage = 'êµ¬ë§¤ ê²°ì •';
        } else if (lowerKeyword.includes('êµ¬ë§¤') || lowerKeyword.includes('êµ¬ì…') || lowerKeyword.includes('ì£¼ë¬¸') || lowerKeyword.includes('ì˜ˆì•½')) {
          stage = 'êµ¬ë§¤ í–‰ë™';
        } else if (lowerKeyword.includes('í›„ê¸°') || lowerKeyword.includes('ë¦¬ë·°') || lowerKeyword.includes('í‰ê°€') || lowerKeyword.includes('ë§Œì¡±')) {
          stage = 'êµ¬ë§¤ í›„ í–‰ë™';
        }
        
        return {
          keyword,
          stage,
        };
      });
      
      return NextResponse.json({ 
        results: dummyResults,
        source: 'dummy',
        message: 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë”ë¯¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.'
      });
    }

    // í‚¤ì›Œë“œ ë°°ì¹˜ ë¶„í•  ë° ë³‘ë ¬ ì²˜ë¦¬
    console.log(`âœ… OpenAI API key found. Processing ${keywords.length} keywords in batches of ${BATCH_SIZE} using ${model}.`);
    
    const keywordBatches = chunkArray(keywords, BATCH_SIZE);
    console.log(`ğŸ“¦ Split into ${keywordBatches.length} batches`);
    
    try {
      // ëª¨ë“  ë°°ì¹˜ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
      const batchPromises = keywordBatches.map((batch, index) => 
        processBatchWithRetry(batch, model, apiKey, index)
      );
      
      console.log(`ğŸš€ Starting parallel processing of ${keywordBatches.length} batches...`);
      const batchResults = await Promise.all(batchPromises);
      
      // ëª¨ë“  ë°°ì¹˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©
      const allResults = batchResults.flat();
      
      console.log(`âœ… Successfully processed all ${keywordBatches.length} batches. Total results: ${allResults.length}`);
      
      return NextResponse.json({ 
        results: allResults,
        source: 'openai',
        model: model,
        totalBatches: keywordBatches.length,
        totalKeywords: keywords.length,
        message: `${model}ì„ ì‚¬ìš©í•˜ì—¬ ${keywordBatches.length}ê°œ ë°°ì¹˜ë¥¼ ë³‘ë ¬ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.`
      });
    } catch (apiError) {
      console.error('âŒ Batch processing error:', apiError);
      
      // ë³‘ë ¬ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
      const fallbackResults = keywords.map((keyword: string) => ({
        keyword,
        stage: 'ì •ë³´ íƒìƒ‰',
      }));
      
      return NextResponse.json({ 
        results: fallbackResults,
        source: 'fallback',
        message: 'ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ë¡œ ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.',
        error: apiError instanceof Error ? apiError.message : 'Unknown error'
      });
    }
  } catch (error) {
    console.error('API Route Error:', error);
    return NextResponse.json(
      { error: 'Failed to analyze buyer journey', details: error instanceof Error ? error.message : 'Unknown error' },
      { status: 500 }
    );
  }
}